/**
 * ä¸¤çº§ç¼“å­˜æœåŠ¡ / Two-Level Cache Service
 *
 * åŠŸèƒ½è¯´æ˜ / Description:
 * æä¾› L1ï¼ˆå†…å­˜ï¼‰+ L2ï¼ˆRedisï¼‰ä¸¤çº§ç¼“å­˜æ¶æ„ï¼Œæ”¯æŒ TTLã€åˆ†å¸ƒå¼åŒæ­¥å’Œè£…é¥°å™¨
 * Provides L1 (memory) + L2 (Redis) two-level cache architecture with TTL, distributed sync, and decorators
 *
 * ä¸»è¦åŠŸèƒ½ / Main Features:
 * 1. L1 ç¼“å­˜ - è¿›ç¨‹å†…å­˜ç¼“å­˜ï¼Œè®¿é—®é€Ÿåº¦æå¿«ï¼ˆå¾®ç§’çº§ï¼‰
 *    L1 Cache - In-process memory cache, extremely fast access (microseconds)
 * 2. L2 ç¼“å­˜ - Redis ç¼“å­˜ï¼Œè·¨è¿›ç¨‹å…±äº«ï¼ˆæ¯«ç§’çº§ï¼‰
 *    L2 Cache - Redis cache, cross-process sharing (milliseconds)
 * 3. TTL æ”¯æŒ - å¯é…ç½®çš„ç¼“å­˜è¿‡æœŸæ—¶é—´
 *    TTL Support - Configurable cache expiration time
 * 4. åˆ†å¸ƒå¼åŒæ­¥ - é€šè¿‡ Redis Pub/Sub åŒæ­¥ L1 ç¼“å­˜
 *    Distributed Sync - Sync L1 cache via Redis Pub/Sub
 * 5. è£…é¥°å™¨æ”¯æŒ - @L1Cache å’Œ @L2Cache æ–¹æ³•è£…é¥°å™¨
 *    Decorator Support - @L1Cache and @L2Cache method decorators
 *
 * ç¼“å­˜æ¶æ„ / Cache Architecture:
 * ```
 * â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 * â”‚  Process 1  â”‚     â”‚  Process 2  â”‚     â”‚  Process 3  â”‚
 * â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚     â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚     â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
 * â”‚ â”‚ L1 Cacheâ”‚ â”‚â—„â”€â”€â”€â”€â”¼â”€â”¤ L1 Cacheâ”‚â”€â”¼â”€â”€â”€â”€â–ºâ”‚ â”‚ L1 Cacheâ”‚ â”‚
 * â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚     â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚     â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
 * â”‚      â–²      â”‚     â”‚      â–²      â”‚     â”‚      â–²      â”‚
 * â”‚      â”‚      â”‚     â”‚      â”‚      â”‚     â”‚      â”‚      â”‚
 * â””â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”˜
 *        â”‚                   â”‚                   â”‚
 *        â”‚    Redis Pub/Sub (CacheServiceEvent)  â”‚
 *        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 *                            â–¼
 *                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 *                   â”‚  Redis (L2)     â”‚
 *                   â”‚  CacheService:* â”‚
 *                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 * ```
 *
 * ä½¿ç”¨ç¤ºä¾‹ / Usage Example:
 * ```typescript
 * import { CacheService, L1Cache, L2Cache } from './libs/cache';
 * import { Service, Inject } from 'typedi';
 *
 * @Service()
 * class UserService {
 *   @Inject()
 *   private cacheService: CacheService;
 *
 *   // æ–¹å¼ 1: è£…é¥°å™¨æ–¹å¼ï¼ˆæ¨èï¼‰/ Method 1: Decorator (recommended)
 *   @L1Cache({ ttlSeconds: 60 })
 *   async getUserById(id: string) {
 *     return await this.db.findUser(id);
 *   }
 *
 *   // æ–¹å¼ 2: æ‰‹åŠ¨æ–¹å¼ / Method 2: Manual
 *   async getUserProfile(id: string) {
 *     return this.cacheService.getL2({ userId: id }, async () => {
 *       return await this.db.findProfile(id);
 *     }, 300);
 *   }
 *
 *   // æ¸…é™¤ç¼“å­˜ / Clear cache
 *   async updateUser(id: string, data: any) {
 *     await this.db.update(id, data);
 *     await this.cacheService.reset({ userId: id });
 *   }
 * }
 * ```
 *
 * æ€§èƒ½å¯¹æ¯” / Performance Comparison:
 * - L1 ç¼“å­˜å‘½ä¸­ï¼š~0.01msï¼ˆå†…å­˜è®¿é—®ï¼‰
 *   L1 cache hit: ~0.01ms (memory access)
 * - L2 ç¼“å­˜å‘½ä¸­ï¼š~1-5msï¼ˆRedis ç½‘ç»œå¾€è¿”ï¼‰
 *   L2 cache hit: ~1-5ms (Redis network roundtrip)
 * - ç¼“å­˜æœªå‘½ä¸­ï¼šå–å†³äºæ•°æ®æºï¼ˆå¯èƒ½ 10-1000ms+ï¼‰
 *   Cache miss: depends on data source (may be 10-1000ms+)
 *
 * æœ€ä½³å®è·µ / Best Practices:
 * - é«˜é¢‘è®¿é—®çš„å°æ•°æ®ä½¿ç”¨ L1 ç¼“å­˜ï¼ˆå¦‚é…ç½®ã€å¸¸é‡ï¼‰
 *   Use L1 cache for frequently accessed small data (e.g., config, constants)
 * - ä¸­é¢‘è®¿é—®çš„å¤§æ•°æ®ä½¿ç”¨ L2 ç¼“å­˜ï¼ˆå¦‚ç”¨æˆ·ä¿¡æ¯ã€åˆ—è¡¨ï¼‰
 *   Use L2 cache for medium-frequency large data (e.g., user info, lists)
 * - æ•°æ®æ›´æ–°æ—¶åŠæ—¶è°ƒç”¨ reset() æ¸…é™¤ç¼“å­˜
 *   Call reset() promptly when data is updated to clear cache
 * - åˆç†è®¾ç½® TTLï¼Œé¿å…å†…å­˜æº¢å‡º
 *   Set reasonable TTL to avoid memory overflow
 */
import Redis from 'ioredis';
import _ from 'lodash';
import Container, { Service } from 'typedi';
import { Logger } from '../logger';
import { RedisClient } from '../redis';
import { fmkTimer } from './Timer';
import { ClassType } from '../type';

/**
 * æ•°æ®æä¾›è€…ç±»å‹ / Data Provider Type
 * ç”¨äºæ‡’åŠ è½½æ•°æ®çš„å›è°ƒå‡½æ•°
 * Callback function for lazy loading data
 *
 * @template T è¿”å›çš„æ•°æ®ç±»å‹ / Return data type
 * @template P å‚æ•°ç±»å‹ / Parameter type
 */
export type DataProvider<T, P = any> = (parma?: P) => T | Promise<T>;

/**
 * å¯¹è±¡è·¯å¾„æ›¿æ¢é…ç½® / Object Path Replace Configuration
 * ç”¨äº applyCache å‡½æ•°çš„è·¯å¾„é…ç½®
 * Path configuration for applyCache function
 */
export type ReplaceObjectPath = { id?: string; value?: string };

/**
 * å®Œæ•´å¯¹è±¡è·¯å¾„é…ç½® / Full Object Path Configuration
 * value å­—æ®µä¸ºå¿…å¡«
 * value field is required
 */
export type ReplaceObjectPathFull = { id?: string; value: string };

/**
 * L1 ç¼“å­˜ TTL ä¿¡æ¯ / L1 Cache TTL Information
 * è®°å½•ç¼“å­˜åˆ›å»ºæ—¶é—´å’Œè¿‡æœŸæ—¶é—´
 * Records cache creation time and expiration time
 */
export type L1TTL = { createdAt: number; ttl: number };

/**
 * ç¼“å­˜æœåŠ¡äº‹ä»¶ / Cache Service Event
 * Redis Pub/Sub æ¶ˆæ¯æ ¼å¼
 * Redis Pub/Sub message format
 */
export type CacheServiceEvent = {
  /** äº‹ä»¶ç±»å‹ / Event type */
  event: string;
  /** äº‹ä»¶å‚æ•° / Event parameter */
  param: any;
  /** äº‹ä»¶å€¼ï¼ˆå¯é€‰ï¼‰/ Event value (optional) */
  value?: any;
} & Partial<L1TTL>;

/**
 * ç¼“å­˜åŒæ­¥å™¨ç±»å‹ / Cache Synchronizer Type
 * ç”¨äºè‡ªå®šä¹‰ç¼“å­˜åŒæ­¥é€»è¾‘ï¼ˆé¢„ç•™æ¥å£ï¼‰
 * For custom cache synchronization logic (reserved interface)
 */
export type CacheSynconizer = (key: string, updaterName: string, val: any) => any;

/**
 * ç¼“å­˜æœåŠ¡äº‹ä»¶å¸¸é‡ / Cache Service Event Constants
 */
export const CacheServiceEvents = {
  /** é‡ç½®ç¼“å­˜äº‹ä»¶ / Reset cache event */
  REST: 'REST',
  /** L1 ç¼“å­˜æ›´æ–°äº‹ä»¶ / L1 cache update event */
  L1_UPDATE: 'L1_UPDATE',
};

/**
 * L1 ç¼“å­˜å­˜å‚¨ / L1 Cache Storage
 * è¿›ç¨‹å†…å­˜ä¸­çš„ç¼“å­˜æ•°æ®
 * Cache data in process memory
 */
const levelOneCache: any = {};

/**
 * L1 ç¼“å­˜ TTL è®°å½• / L1 Cache TTL Records
 * è®°å½•æ¯ä¸ªç¼“å­˜çš„åˆ›å»ºæ—¶é—´å’Œè¿‡æœŸæ—¶é—´
 * Records creation and expiration time for each cache
 */
const levelOneCacheTTL: Record<any, L1TTL> = {};

/**
 * L1 ç¼“å­˜å®šä¹‰ / L1 Cache Definitions
 * ä¿å­˜ L1 ç¼“å­˜çš„æ•°æ®æä¾›è€…å‡½æ•°
 * Stores data provider functions for L1 cache
 */
const l1Definitions: Record<string, DataProvider<any, any>> = {};

/**
 * L2 ç¼“å­˜å®šä¹‰ / L2 Cache Definitions
 * ä¿å­˜ L2 ç¼“å­˜çš„æ•°æ®æä¾›è€…å‡½æ•°
 * Stores data provider functions for L2 cache
 */
const l2Definitions: Record<string, DataProvider<any, any>> = {};

/**
 * è·å– Redis ç¼“å­˜é”® / Get Redis Cache Key
 * ä¸ºç¼“å­˜é”®æ·»åŠ ç»Ÿä¸€å‰ç¼€ï¼Œé¿å…ä¸å…¶ä»– Redis é”®å†²çª
 * Adds uniform prefix to cache keys to avoid conflicts with other Redis keys
 *
 * @param key åŸå§‹ç¼“å­˜é”® / Original cache key
 * @returns å¸¦å‰ç¼€çš„ Redis é”® / Prefixed Redis key
 */
const getCacheServiceKey = (key: string) => `CacheService:${key}`;

/**
 * ç¼“å­˜æœåŠ¡ç±» / Cache Service Class
 *
 * æ¶æ„è¯´æ˜ / Architecture:
 * - L1 ç¼“å­˜ï¼šä½¿ç”¨è¿›ç¨‹å†…å­˜ï¼ˆlevelOneCache å¯¹è±¡ï¼‰
 *   L1 Cache: Uses process memory (levelOneCache object)
 * - L2 ç¼“å­˜ï¼šä½¿ç”¨ Redis å­˜å‚¨ï¼ˆCacheService:* é”®ï¼‰
 *   L2 Cache: Uses Redis storage (CacheService:* keys)
 * - åŒæ­¥æœºåˆ¶ï¼šRedis Pub/Sub é¢‘é“ 'CacheServiceEvent'
 *   Sync mechanism: Redis Pub/Sub channel 'CacheServiceEvent'
 * - TTL æ£€æŸ¥ï¼šé€šè¿‡ Timer å®šæœŸæ¸…ç†è¿‡æœŸçš„ L1 ç¼“å­˜
 *   TTL check: Periodically clean expired L1 cache via Timer
 *
 * ç”Ÿå‘½å‘¨æœŸ / Lifecycle:
 * 1. æ„é€ å‡½æ•°åˆ›å»ºä¸¤ä¸ª Redis è¿æ¥ï¼ˆè®¢é˜… + æ“ä½œï¼‰
 *    Constructor creates two Redis connections (subscribe + operations)
 * 2. è®¢é˜… CacheServiceEvent é¢‘é“ç›‘å¬ç¼“å­˜äº‹ä»¶
 *    Subscribe to CacheServiceEvent channel to listen for cache events
 * 3. å¯åŠ¨å®šæ—¶å™¨å®šæœŸæ£€æŸ¥ L1 ç¼“å­˜è¿‡æœŸ
 *    Start timer to periodically check L1 cache expiration
 */
@Service()
export class CacheService {
  /** æ—¥å¿—è®°å½•å™¨ / Logger instance */
  logger = Logger.getLogger(CacheService);

  /**
   * æ„é€ å‡½æ•° / Constructor
   *
   * @param redisClient Redis å®¢æˆ·ç«¯å®ä¾‹ / Redis client instance
   *
   * è¯´æ˜ / Description:
   * åˆ›å»ºä¸¤ä¸ªç‹¬ç«‹çš„ Redis è¿æ¥ï¼š
   * Creates two independent Redis connections:
   * - redisSub: ä¸“ç”¨äº Pub/Sub è®¢é˜…ï¼ˆé¿å…é˜»å¡ï¼‰
   *   Dedicated for Pub/Sub subscription (avoid blocking)
   * - redis: ç”¨äºæ™®é€š Redis æ“ä½œï¼ˆGET/SET/DELï¼‰
   *   For normal Redis operations (GET/SET/DEL)
   */
  constructor(private redisClient: RedisClient) {
    this.startCacheService(redisClient.newClient(), redisClient.newClient());
  }

  /**
   * å¯åŠ¨ç¼“å­˜æœåŠ¡ / Start Cache Service
   *
   * @param redisSub Redis è®¢é˜…å®¢æˆ·ç«¯ / Redis subscription client
   * @param redis Redis æ“ä½œå®¢æˆ·ç«¯ / Redis operations client
   *
   * åŠŸèƒ½è¯´æ˜ / Description:
   * åˆå§‹åŒ–åˆ†å¸ƒå¼ç¼“å­˜åŒæ­¥ç³»ç»Ÿï¼Œç›‘å¬ç¼“å­˜äº‹ä»¶
   * Initializes distributed cache sync system, listens for cache events
   *
   * äº‹ä»¶å¤„ç† / Event Handling:
   * - REST: é‡ç½®æŒ‡å®šé”®çš„ L1 å’Œ L2 ç¼“å­˜
   *   Reset L1 and L2 cache for specified key
   * - L1_UPDATE: æ›´æ–°æŒ‡å®šé”®çš„ L1 ç¼“å­˜
   *   Update L1 cache for specified key
   *
   * å®šæ—¶ä»»åŠ¡ / Scheduled Task:
   * æ¯ç§’æ£€æŸ¥ä¸€æ¬¡ L1 ç¼“å­˜è¿‡æœŸæƒ…å†µ
   * Check L1 cache expiration every second
   */
  public startCacheService(redisSub: Redis, redis: Redis) {
    // è®¢é˜… CacheServiceEvent é¢‘é“ / Subscribe to CacheServiceEvent channel
    redisSub.subscribe('CacheServiceEvent', (err) => {
      if (err) {
        this.logger.error(err.message);
      } else {
        this.logger.info(`ğŸš€CacheService level 2 cache(redis) subscribed successfully!`);
      }
    });

    // ç›‘å¬ç¼“å­˜äº‹ä»¶æ¶ˆæ¯ / Listen for cache event messages
    redisSub.on('message', (__, message: string) => {
      const logger = Logger.getLogger(CacheService);
      const { event, param, value, ttl, createdAt }: CacheServiceEvent = JSON.parse(message);

      // å¤„ç†é‡ç½®ç¼“å­˜äº‹ä»¶ / Handle reset cache event
      if (event === CacheServiceEvents.REST) {
        // åˆ é™¤ L1 ç¼“å­˜ / Delete L1 cache
        if (levelOneCache[param]) {
          delete levelOneCache[param];
          delete levelOneCacheTTL[param];
          logger.info('Reset level 1 cache: %s', param);
        }
        // åˆ é™¤ L2 ç¼“å­˜ / Delete L2 cache
        redis.del(getCacheServiceKey(param)).then((n) => {
          if (n > 0) logger.info('Reset level 2 cache: %s', param);
        });
      }

      // å¤„ç† L1 ç¼“å­˜æ›´æ–°äº‹ä»¶ / Handle L1 cache update event
      if (event === CacheServiceEvents.L1_UPDATE) {
        levelOneCache[param] = value;
        // å¦‚æœæœ‰ TTLï¼Œè®°å½•è¿‡æœŸæ—¶é—´ / If TTL exists, record expiration time
        if (ttl && createdAt) {
          levelOneCacheTTL[param] = {
            ttl,
            createdAt,
          };
        }
        logger.info('Update level 1 cache: %s', param);
      }
    });

    // æ³¨å†Œå®šæ—¶å™¨ï¼Œæ¯ç§’æ£€æŸ¥ L1 ç¼“å­˜è¿‡æœŸ / Register timer to check L1 cache expiration every second
    fmkTimer.onTimer('CacheService:CacheChecker', () => {
      const now = Date.now();
      // æ‰¾å‡ºæ‰€æœ‰è¿‡æœŸçš„ç¼“å­˜é”® / Find all expired cache keys
      Object.keys(levelOneCacheTTL)
        .filter((key) => {
          const { createdAt, ttl } = levelOneCacheTTL[key];
          return createdAt + ttl * 1000 < now; // æ£€æŸ¥æ˜¯å¦è¿‡æœŸ / Check if expired
        })
        .forEach((key) => {
          // åˆ é™¤è¿‡æœŸç¼“å­˜ / Delete expired cache
          delete levelOneCache[key];
          delete levelOneCacheTTL[key];
        });
    });
  }

  /**
   * é‡ç½®ç¼“å­˜ / Reset Cache
   *
   * @param param ç¼“å­˜å‚æ•°ï¼ˆç”¨äºç”Ÿæˆç¼“å­˜é”®ï¼‰/ Cache parameter (used to generate cache key)
   *
   * åŠŸèƒ½è¯´æ˜ / Description:
   * å‘æ‰€æœ‰è¿›ç¨‹å¹¿æ’­é‡ç½®ç¼“å­˜äº‹ä»¶ï¼Œæ¸…é™¤ L1 å’Œ L2 ç¼“å­˜
   * Broadcasts reset cache event to all processes to clear L1 and L2 cache
   *
   * ä½¿ç”¨åœºæ™¯ / Use Cases:
   * - æ•°æ®æ›´æ–°åæ¸…é™¤ç¼“å­˜ / Clear cache after data update
   * - å¼ºåˆ¶åˆ·æ–°ç¼“å­˜ / Force cache refresh
   *
   * ç¤ºä¾‹ / Example:
   * ```typescript
   * // ç”¨æˆ·ä¿¡æ¯æ›´æ–°åæ¸…é™¤ç¼“å­˜ / Clear cache after user info update
   * await this.cacheService.reset({ userId: '123' });
   * ```
   */
  async reset<P>(param: P) {
    await this.redisClient.redis.publish('CacheServiceEvent', JSON.stringify({ event: CacheServiceEvents.REST, param: JSON.stringify(param) }));
  }

  /**
   * åˆ›å»º L1 ç¼“å­˜æ•°æ®æä¾›è€… / Create L1 Cache Data Provider
   *
   * @param param ç¼“å­˜å‚æ•° / Cache parameter
   * @param provider æ•°æ®æä¾›è€…å‡½æ•° / Data provider function
   * @param ttlSeconds TTLï¼ˆç§’ï¼‰ï¼Œå¯é€‰ / TTL in seconds, optional
   * @returns å¸¦ç¼“å­˜çš„æ•°æ®æä¾›è€… / Data provider with caching
   *
   * åŠŸèƒ½è¯´æ˜ / Description:
   * è¿”å›ä¸€ä¸ªæ‡’åŠ è½½å‡½æ•°ï¼Œé¦–æ¬¡è°ƒç”¨æ—¶è·å–æ•°æ®å¹¶ç¼“å­˜åˆ° L1
   * Returns a lazy-loading function that fetches data on first call and caches to L1
   *
   * ç¼“å­˜ç­–ç•¥ / Caching Strategy:
   * 1. æ£€æŸ¥ L1 ç¼“å­˜æ˜¯å¦å­˜åœ¨ / Check if L1 cache exists
   * 2. ä¸å­˜åœ¨åˆ™è°ƒç”¨ provider è·å–æ•°æ® / If not, call provider to fetch data
   * 3. é€šè¿‡ Redis Pub/Sub å¹¿æ’­åˆ°æ‰€æœ‰è¿›ç¨‹ / Broadcast to all processes via Redis Pub/Sub
   * 4. æ‰€æœ‰è¿›ç¨‹æ›´æ–°æœ¬åœ° L1 ç¼“å­˜ / All processes update local L1 cache
   *
   * ç¤ºä¾‹ / Example:
   * ```typescript
   * const getCfg = cacheService.L1({ key: 'app-config' }, async () => {
   *   return await loadConfigFromDB();
   * }, 300);
   *
   * const config = await getCfg(); // ç¬¬ä¸€æ¬¡è°ƒç”¨åŠ è½½æ•°æ® / First call loads data
   * const config2 = await getCfg(); // åç»­è°ƒç”¨è¿”å›ç¼“å­˜ / Subsequent calls return cache
   * ```
   */
  L1<T, P>(param: P, provider: DataProvider<T, P>, ttlSeconds?: number): DataProvider<T, P> {
    l1Definitions[JSON.stringify(param)] = provider; // ä¿å­˜æ•°æ®æä¾›è€…å®šä¹‰ / Save data provider definition
    return async (parma?: P): Promise<T> => {
      const key = JSON.stringify(parma);
      let value = levelOneCache[key]; // æ£€æŸ¥ L1 ç¼“å­˜ / Check L1 cache

      if (_.isNil(value)) {
        // L1 ç¼“å­˜æœªå‘½ä¸­ï¼Œè°ƒç”¨ provider è·å–æ•°æ® / L1 cache miss, call provider to fetch data
        value = await Promise.resolve(provider(parma));
        if (!_.isNil(value)) {
          // å¹¿æ’­ L1 ç¼“å­˜æ›´æ–°äº‹ä»¶ / Broadcast L1 cache update event
          if (ttlSeconds) {
            // å¸¦ TTL çš„ç¼“å­˜ / Cache with TTL
            await this.redisClient.redis.publish(
              'CacheServiceEvent',
              JSON.stringify({
                event: CacheServiceEvents.L1_UPDATE,
                param: key,
                value,
                createdAt: Date.now(),
                ttl: ttlSeconds,
              } as CacheServiceEvent),
            );
          } else {
            // æ°¸ä¹…ç¼“å­˜ï¼ˆæ—  TTLï¼‰/ Permanent cache (no TTL)
            await this.redisClient.redis.publish(
              'CacheServiceEvent',
              JSON.stringify({
                event: CacheServiceEvents.L1_UPDATE,
                param: key,
                value,
              } as CacheServiceEvent),
            );
          }
        }
      }
      return value;
    };
  }

  /**
   * è·å– L1 ç¼“å­˜æ•°æ®ï¼ˆå¿«æ·æ–¹æ³•ï¼‰/ Get L1 Cache Data (Shortcut Method)
   *
   * @param param ç¼“å­˜å‚æ•° / Cache parameter
   * @param provider æ•°æ®æä¾›è€… / Data provider
   * @param expire TTLï¼ˆç§’ï¼‰/ TTL in seconds
   * @returns ç¼“å­˜æ•°æ® / Cached data
   *
   * åŠŸèƒ½è¯´æ˜ / Description:
   * L1() æ–¹æ³•çš„å¿«æ·ç‰ˆæœ¬ï¼Œç›´æ¥è¿”å›æ•°æ®è€Œä¸æ˜¯æ•°æ®æä¾›è€…
   * Shortcut version of L1() that returns data directly instead of data provider
   */
  async getL1<T, P>(param: P, provider: DataProvider<T, P>, expire?: number) {
    return this.L1(param, provider, expire)(param);
  }

  /**
   * åˆ›å»º L2 ç¼“å­˜æ•°æ®æä¾›è€… / Create L2 Cache Data Provider
   *
   * @param param ç¼“å­˜å‚æ•° / Cache parameter
   * @param provider æ•°æ®æä¾›è€…å‡½æ•° / Data provider function
   * @param ttlSeconds TTLï¼ˆç§’ï¼‰ï¼Œå¯é€‰ / TTL in seconds, optional
   * @returns å¸¦ç¼“å­˜çš„æ•°æ®æä¾›è€… / Data provider with caching
   *
   * åŠŸèƒ½è¯´æ˜ / Description:
   * è¿”å›ä¸€ä¸ªæ‡’åŠ è½½å‡½æ•°ï¼Œé¦–æ¬¡è°ƒç”¨æ—¶è·å–æ•°æ®å¹¶ç¼“å­˜åˆ° Redis (L2)
   * Returns a lazy-loading function that fetches data on first call and caches to Redis (L2)
   *
   * ç¼“å­˜ç­–ç•¥ / Caching Strategy:
   * 1. æ£€æŸ¥ Redis ç¼“å­˜æ˜¯å¦å­˜åœ¨ / Check if Redis cache exists
   * 2. ä¸å­˜åœ¨åˆ™è°ƒç”¨ provider è·å–æ•°æ® / If not, call provider to fetch data
   * 3. å°†æ•°æ®å­˜å‚¨åˆ° Redis / Store data to Redis
   * 4. å¦‚æœæŒ‡å®š TTLï¼Œè®¾ç½®è¿‡æœŸæ—¶é—´ / If TTL specified, set expiration
   *
   * ä¸ L1 çš„åŒºåˆ« / Difference from L1:
   * - L2 ç¼“å­˜è·¨è¿›ç¨‹å…±äº«ï¼Œä¸éœ€è¦ Pub/Sub åŒæ­¥
   *   L2 cache is shared across processes, no Pub/Sub sync needed
   * - L2 ç¼“å­˜è®¿é—®è¾ƒæ…¢ï¼ˆç½‘ç»œ IOï¼‰ï¼Œé€‚åˆä¸­é¢‘è®¿é—®åœºæ™¯
   *   L2 cache access is slower (network IO), suitable for medium-frequency scenarios
   *
   * ç¤ºä¾‹ / Example:
   * ```typescript
   * const getUser = cacheService.L2({ userId: '123' }, async () => {
   *   return await userRepo.findById('123');
   * }, 600);
   *
   * const user = await getUser(); // ä»æ•°æ®åº“åŠ è½½ / Load from database
   * const user2 = await getUser(); // ä» Redis è¿”å› / Return from Redis
   * ```
   */
  L2<T, P>(param: P, provider: DataProvider<T, P>, ttlSeconds?: number): DataProvider<T, P> {
    l2Definitions[JSON.stringify(param)] = provider; // ä¿å­˜æ•°æ®æä¾›è€…å®šä¹‰ / Save data provider definition
    return async (parma?: P): Promise<T> => {
      const key = getCacheServiceKey(JSON.stringify(parma));
      const valueStr = await this.redisClient.redis.get(key); // æ£€æŸ¥ L2 ç¼“å­˜ / Check L2 cache

      if (_.isNil(valueStr)) {
        // L2 ç¼“å­˜æœªå‘½ä¸­ï¼Œè°ƒç”¨ provider è·å–æ•°æ® / L2 cache miss, call provider to fetch data
        const value = await Promise.resolve(provider(parma));
        if (!_.isNil(value)) {
          // å­˜å‚¨åˆ° Redis / Store to Redis
          await this.redisClient.redis.set(key, JSON.stringify(value));
          // å¦‚æœæŒ‡å®š TTLï¼Œè®¾ç½®è¿‡æœŸæ—¶é—´ / If TTL specified, set expiration
          if (ttlSeconds) {
            await this.redisClient.redis.expire(key, ttlSeconds);
          }
        }
        return value;
      } else {
        // L2 ç¼“å­˜å‘½ä¸­ï¼Œååºåˆ—åŒ–å¹¶è¿”å› / L2 cache hit, deserialize and return
        return JSON.parse(valueStr);
      }
    };
  }

  /**
   * è·å– L2 ç¼“å­˜æ•°æ®ï¼ˆå¿«æ·æ–¹æ³•ï¼‰/ Get L2 Cache Data (Shortcut Method)
   *
   * @param param ç¼“å­˜å‚æ•° / Cache parameter
   * @param provider æ•°æ®æä¾›è€… / Data provider
   * @param expire TTLï¼ˆç§’ï¼‰/ TTL in seconds
   * @returns ç¼“å­˜æ•°æ® / Cached data
   *
   * åŠŸèƒ½è¯´æ˜ / Description:
   * L2() æ–¹æ³•çš„å¿«æ·ç‰ˆæœ¬ï¼Œç›´æ¥è¿”å›æ•°æ®è€Œä¸æ˜¯æ•°æ®æä¾›è€…
   * Shortcut version of L2() that returns data directly instead of data provider
   */
  async getL2<T, P>(param: P, provider: DataProvider<T, P>, expire?: number) {
    return this.L2(param, provider, expire)(param);
  }

  /**
   * åˆ›å»ºç¼“å­˜ / Create Cache
   *
   * @param key ç¼“å­˜é”® / Cache key
   * @param cb æ•°æ®å›è°ƒå‡½æ•° / Data callback function
   *
   * åŠŸèƒ½è¯´æ˜ / Description:
   * ç›´æ¥åˆ›å»º L2 ç¼“å­˜ï¼Œä¸æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ï¼ˆä¼šè¦†ç›–ï¼‰
   * Directly creates L2 cache without checking existence (will overwrite)
   *
   * ä½¿ç”¨åœºæ™¯ / Use Cases:
   * - é¢„çƒ­ç¼“å­˜ / Cache warming
   * - å¼ºåˆ¶æ›´æ–°ç¼“å­˜ / Force cache update
   */
  async createCache<T = any>(key: any, cb: () => T | Promise<T>) {
    const cacheKey = JSON.stringify(key);
    const cacheData = await Promise.resolve(cb());
    if (!_.isNil(cacheData)) {
      await this.redisClient.redis.set(getCacheServiceKey(cacheKey), JSON.stringify(cacheData));
    }
  }

  /**
   * æ›´æ–°ç¼“å­˜ / Update Cache
   *
   * @param key ç¼“å­˜é”® / Cache key
   * @param cb æ›´æ–°å›è°ƒå‡½æ•°ï¼Œæ¥æ”¶å½“å‰å€¼å¹¶è¿”å›æ–°å€¼ / Update callback that receives current value and returns new value
   *
   * åŠŸèƒ½è¯´æ˜ / Description:
   * è¯»å–å½“å‰ç¼“å­˜å€¼ï¼Œè°ƒç”¨å›è°ƒå‡½æ•°ç”Ÿæˆæ–°å€¼ï¼Œç„¶åæ›´æ–°ç¼“å­˜
   * Reads current cache value, calls callback to generate new value, then updates cache
   *
   * ä½¿ç”¨åœºæ™¯ / Use Cases:
   * - åŸºäºå½“å‰å€¼çš„å¢é‡æ›´æ–° / Incremental update based on current value
   * - æ¡ä»¶æ›´æ–°ç¼“å­˜ / Conditional cache update
   *
   * ç¤ºä¾‹ / Example:
   * ```typescript
   * // å¢åŠ è®¿é—®è®¡æ•° / Increment view count
   * await cacheService.updateCache({ pageId: '123' }, (current) => {
   *   return { ...current, views: (current?.views || 0) + 1 };
   * });
   * ```
   */
  async updateCache<T = any>(key: any, cb: (currentVal?: T) => (T | undefined) | Promise<T | undefined>) {
    const cacheKey = JSON.stringify(key);
    const redisCacheKey = getCacheServiceKey(cacheKey);
    // è¯»å–å½“å‰ç¼“å­˜å€¼ / Read current cache value
    const currentDataStr = await this.redisClient.redis.get(redisCacheKey);
    const currentData = JSON.parse(currentDataStr ?? 'null');
    // è°ƒç”¨å›è°ƒå‡½æ•°ç”Ÿæˆæ–°å€¼ / Call callback to generate new value
    const cacheData = await Promise.resolve(cb(currentData ?? undefined));
    if (!_.isNil(cacheData)) {
      // æ›´æ–°ç¼“å­˜ / Update cache
      await this.redisClient.redis.set(redisCacheKey, JSON.stringify(cacheData));
    }
  }

  /**
   * åˆ é™¤ç¼“å­˜ / Remove Cache
   *
   * @param key ç¼“å­˜é”® / Cache key
   *
   * åŠŸèƒ½è¯´æ˜ / Description:
   * ä» Redis åˆ é™¤æŒ‡å®šçš„ L2 ç¼“å­˜
   * Deletes specified L2 cache from Redis
   *
   * æ³¨æ„äº‹é¡¹ / Notes:
   * - åªåˆ é™¤ L2 ç¼“å­˜ï¼Œä¸å½±å“ L1 ç¼“å­˜
   *   Only deletes L2 cache, does not affect L1 cache
   * - å¦‚éœ€åˆ é™¤ L1+L2ï¼Œä½¿ç”¨ reset() æ–¹æ³•
   *   Use reset() to delete both L1 and L2
   */
  async removeCache(key: any) {
    const cacheKey = JSON.stringify(key);
    const redisCacheKey = getCacheServiceKey(cacheKey);
    await this.redisClient.redis.del(redisCacheKey);
  }

  /**
   * è·å–ç¼“å­˜ / Get Cache
   *
   * @param key ç¼“å­˜é”® / Cache key
   * @returns ç¼“å­˜æ•°æ®æˆ– null / Cache data or null
   *
   * åŠŸèƒ½è¯´æ˜ / Description:
   * ç›´æ¥ä» Redis è¯»å–ç¼“å­˜ï¼Œä¸è§¦å‘æ•°æ®æä¾›è€…
   * Directly reads cache from Redis without triggering data provider
   *
   * ä½¿ç”¨åœºæ™¯ / Use Cases:
   * - æ£€æŸ¥ç¼“å­˜æ˜¯å¦å­˜åœ¨ / Check if cache exists
   * - è¯»å–æ‰‹åŠ¨è®¾ç½®çš„ç¼“å­˜ / Read manually set cache
   */
  async getCache<T = any>(key: any) {
    const cacheKey = JSON.stringify(key);
    const redisCacheKey = getCacheServiceKey(cacheKey);
    const currentDataStr = await this.redisClient.redis.get(redisCacheKey);
    const currentData = JSON.parse(currentDataStr ?? 'null') as T | null;
    return currentData;
  }

  /**
   * æ‰¹é‡è·å–ç¼“å­˜ / Get Multiple Caches
   *
   * @param keys ç¼“å­˜é”®æ•°ç»„ / Array of cache keys
   * @returns ç¼“å­˜æ•°æ®æ•°ç»„ / Array of cache data
   *
   * åŠŸèƒ½è¯´æ˜ / Description:
   * ä½¿ç”¨ Redis MGET å‘½ä»¤æ‰¹é‡è·å–å¤šä¸ªç¼“å­˜
   * Uses Redis MGET command to fetch multiple caches in batch
   *
   * æ€§èƒ½ä¼˜åŠ¿ / Performance Advantage:
   * ä¸€æ¬¡ç½‘ç»œå¾€è¿”è·å–å¤šä¸ªé”®ï¼Œæ¯”å¾ªç¯è°ƒç”¨ getCache() å¿«
   * Fetches multiple keys in one network roundtrip, faster than looping getCache()
   *
   * ç¤ºä¾‹ / Example:
   * ```typescript
   * const keys = [{ userId: '1' }, { userId: '2' }, { userId: '3' }];
   * const users = await cacheService.getCaches<User>(keys);
   * // users: [User|null, User|null, User|null]
   * ```
   */
  async getCaches<T = any>(keys: any[]) {
    const cacheKeys = keys.map((key) => JSON.stringify(key));
    const redisCacheKeys = cacheKeys.map((cacheKey) => getCacheServiceKey(cacheKey));
    // ä½¿ç”¨ MGET æ‰¹é‡è·å– / Use MGET to fetch in batch
    const currentDataStrArray = await this.redisClient.redis.mget(redisCacheKeys);
    // ååºåˆ—åŒ–æ‰€æœ‰ç»“æœ / Deserialize all results
    const currentDataArray = currentDataStrArray.map((currentDataStr) => JSON.parse(currentDataStr ?? 'null') as T | null);
    return currentDataArray;
  }
}

/**
 * åˆ›å»ºç¼“å­˜ï¼ˆå…¨å±€å‡½æ•°ï¼‰/ Create Cache (Global Function)
 *
 * @param key ç¼“å­˜é”® / Cache key
 * @param cb æ•°æ®å›è°ƒ / Data callback
 *
 * åŠŸèƒ½è¯´æ˜ / Description:
 * å…¨å±€å¿«æ·å‡½æ•°ï¼Œæ— éœ€æ³¨å…¥ CacheService
 * Global shortcut function, no need to inject CacheService
 */
export const createCache = async <T = any>(key: any, cb: () => T | Promise<T>) => {
  const cacheService = Container.get(CacheService);
  await cacheService.createCache(key, cb);
};

/**
 * æ›´æ–°ç¼“å­˜ï¼ˆå…¨å±€å‡½æ•°ï¼‰/ Update Cache (Global Function)
 * å…¨å±€å¿«æ·å‡½æ•°ï¼Œæ— éœ€æ³¨å…¥ CacheService
 * Global shortcut function, no need to inject CacheService
 */
export const updateCache = async <T = any>(key: any, cb: (currentVal?: T) => (T | undefined) | Promise<T | undefined>) => {
  const cacheService = Container.get(CacheService);
  await cacheService.updateCache(key, cb);
};

/**
 * åˆ é™¤ç¼“å­˜ï¼ˆå…¨å±€å‡½æ•°ï¼‰/ Remove Cache (Global Function)
 * å…¨å±€å¿«æ·å‡½æ•°ï¼Œæ— éœ€æ³¨å…¥ CacheService
 * Global shortcut function, no need to inject CacheService
 */
export const removeCache = async (key: any) => {
  const cacheService = Container.get(CacheService);
  await cacheService.removeCache(key);
};

/**
 * è·å–ç¼“å­˜ï¼ˆå…¨å±€å‡½æ•°ï¼‰/ Get Cache (Global Function)
 * å…¨å±€å¿«æ·å‡½æ•°ï¼Œæ— éœ€æ³¨å…¥ CacheService
 * Global shortcut function, no need to inject CacheService
 */
export const getCache = async <T = any>(key: any) => {
  const cacheService = Container.get(CacheService);
  return cacheService.getCache<T>(key);
};

/**
 * æ‰¹é‡è·å–ç¼“å­˜ï¼ˆå…¨å±€å‡½æ•°ï¼‰/ Get Caches (Global Function)
 * å…¨å±€å¿«æ·å‡½æ•°ï¼Œæ— éœ€æ³¨å…¥ CacheService
 * Global shortcut function, no need to inject CacheService
 */
export const getCaches = async <T = any>(keys: any[]) => {
  const cacheService = Container.get(CacheService);
  return cacheService.getCaches<T>(keys);
};

/**
 * é‡ç½®ç¼“å­˜ï¼ˆå…¨å±€å‡½æ•°ï¼‰/ Reset Cache (Global Function)
 *
 * @param param ç¼“å­˜å‚æ•° / Cache parameter
 *
 * åŠŸèƒ½è¯´æ˜ / Description:
 * å…¨å±€å¿«æ·å‡½æ•°ï¼Œæ— éœ€æ³¨å…¥ CacheService
 * Global shortcut function, no need to inject CacheService
 */
export function resetCache<P>(param: P) {
  const cacheService = Container.get(CacheService);
  cacheService.reset(param);
}

/**
 * åº”ç”¨ç¼“å­˜åˆ°å¯¹è±¡ / Apply Cache to Object
 *
 * @param target ç›®æ ‡å¯¹è±¡æˆ–æ•°ç»„ / Target object or array
 * @param targetPath ç›®æ ‡å¯¹è±¡è·¯å¾„é…ç½® / Target object path configuration
 * @param cache ç¼“å­˜æ•°æ®æ•°ç»„ / Cache data array
 * @param cachePath ç¼“å­˜å¯¹è±¡è·¯å¾„é…ç½® / Cache object path configuration
 * @param clone æ˜¯å¦å…‹éš†å¯¹è±¡ï¼Œé»˜è®¤ false / Whether to clone object, default false
 * @returns å¤„ç†åçš„å¯¹è±¡ / Processed object
 *
 * åŠŸèƒ½è¯´æ˜ / Description:
 * å°†ç¼“å­˜æ•°æ®åº”ç”¨åˆ°ç›®æ ‡å¯¹è±¡ï¼Œæ›¿æ¢æŒ‡å®šå­—æ®µçš„å€¼
 * Applies cache data to target object, replacing specified field values
 *
 * ä½¿ç”¨åœºæ™¯ / Use Cases:
 * - ç”¨ç¼“å­˜çš„ç”¨æˆ·åæ›¿æ¢ç”¨æˆ· ID / Replace user ID with cached username
 * - ç”¨ç¼“å­˜çš„åˆ†ç±»åæ›¿æ¢åˆ†ç±» ID / Replace category ID with cached category name
 * - æ‰¹é‡æ•°æ®çš„å­—æ®µå¡«å…… / Field filling for batch data
 *
 * ç¤ºä¾‹ / Example:
 * ```typescript
 * const posts = [
 *   { id: 1, authorId: 'u1', title: 'Post 1' },
 *   { id: 2, authorId: 'u2', title: 'Post 2' },
 * ];
 * const userCache = [
 *   { id: 'u1', name: 'Alice' },
 *   { id: 'u2', name: 'Bob' },
 * ];
 *
 * const result = applyCache(
 *   posts,
 *   { id: 'authorId', value: 'authorName' }, // ç›®æ ‡ï¼šä» authorId åŒ¹é…ï¼Œå†™å…¥ authorName
 *   userCache,
 *   { id: 'id', value: 'name' }, // ç¼“å­˜ï¼šä» id åŒ¹é…ï¼Œå– name å€¼
 * );
 * // result: [
 * //   { id: 1, authorId: 'u1', title: 'Post 1', authorName: 'Alice' },
 * //   { id: 2, authorId: 'u2', title: 'Post 2', authorName: 'Bob' },
 * // ]
 * ```
 */
export function applyCache<T, C>(target: T, targetPath: ReplaceObjectPath, cache: C[], cachePath: ReplaceObjectPathFull, clone = false) {
  const targetData = clone ? _.cloneDeep(target) : target;
  if (Array.isArray(targetData)) {
    // æ•°ç»„æƒ…å†µï¼šå¯¹æ¯ä¸ªå…ƒç´ åº”ç”¨ç¼“å­˜ / Array case: apply cache to each element
    targetData.forEach((t) => replaceObj(t, targetPath, cache, cachePath));
  } else {
    // å•ä¸ªå¯¹è±¡æƒ…å†µ / Single object case
    replaceObj(targetData, targetPath, cache, cachePath);
  }
  return targetData;
}

/**
 * æ›¿æ¢å¯¹è±¡å­—æ®µ / Replace Object Field
 * applyCache çš„å†…éƒ¨è¾…åŠ©å‡½æ•°
 * Internal helper function for applyCache
 */
function replaceObj(target: any, targetPath: ReplaceObjectPath, cache: any[], cachePath: ReplaceObjectPathFull) {
  // ä»ç¼“å­˜ä¸­æ‰¾åˆ°åŒ¹é…çš„æ•°æ® / Find matching data from cache
  const data = cache.find((c) => _.isEqual(c[cachePath.id ?? 'id'], target[targetPath.id ?? 'id']));
  const value = data[cachePath.value];
  // å°†ç¼“å­˜å€¼å†™å…¥ç›®æ ‡å¯¹è±¡ / Write cache value to target object
  target[targetPath.value ?? cachePath.value] = value;
}

/**
 * TTL ç§’æ•°å‡½æ•°ç±»å‹ / TTL Seconds Function Type
 * æ”¯æŒåŠ¨æ€è®¡ç®— TTL å€¼
 * Supports dynamic TTL calculation
 */
export type TTLSecondFn = (get: <T>(claz: ClassType<T>) => T) => number | Promise<number>;

/**
 * ç¼“å­˜é€‰é¡¹ç±»å‹ / Cache Option Type
 * ç”¨äº @L1Cache å’Œ @L2Cache è£…é¥°å™¨
 * For @L1Cache and @L2Cache decorators
 */
export type CacheOption = {
  /** è‡ªå®šä¹‰ç¼“å­˜é”®ï¼Œå¯é€‰ / Custom cache key, optional */
  key?: any;
  /** TTLï¼ˆç§’ï¼‰ï¼Œå¯ä»¥æ˜¯æ•°å­—æˆ–å‡½æ•° / TTL in seconds, can be number or function */
  ttlSeconds?: number | TTLSecondFn;
};

/**
 * L1 ç¼“å­˜è£…é¥°å™¨ / L1 Cache Decorator
 *
 * @param option ç¼“å­˜é€‰é¡¹ / Cache options
 * @returns æ–¹æ³•è£…é¥°å™¨ / Method decorator
 *
 * åŠŸèƒ½è¯´æ˜ / Description:
 * ä¸ºæ–¹æ³•æ·»åŠ  L1 ç¼“å­˜ï¼Œé¦–æ¬¡è°ƒç”¨ç¼“å­˜ç»“æœï¼Œåç»­è°ƒç”¨è¿”å›ç¼“å­˜
 * Adds L1 cache to method, caches result on first call, returns cache on subsequent calls
 *
 * ä½¿ç”¨åœºæ™¯ / Use Cases:
 * - é«˜é¢‘è®¿é—®çš„é…ç½®æ•°æ® / Frequently accessed config data
 * - è®¡ç®—å¯†é›†å‹æ–¹æ³• / Compute-intensive methods
 * - çŸ­æœŸæœ‰æ•ˆçš„æ•°æ® / Short-term valid data
 *
 * ç¤ºä¾‹ / Example:
 * ```typescript
 * @Service()
 * class ConfigService {
 *   @L1Cache({ ttlSeconds: 60 })
 *   async getAppConfig() {
 *     return await this.configRepo.find();
 *   }
 *
 *   // è‡ªå®šä¹‰ç¼“å­˜é”® / Custom cache key
 *   @L1Cache({ key: 'user-settings', ttlSeconds: 300 })
 *   async getUserSettings(userId: string) {
 *     return await this.db.findSettings(userId);
 *   }
 * }
 * ```
 */
export function L1Cache(option?: CacheOption) {
  return cache(option ?? {}, true);
}

/**
 * L2 ç¼“å­˜è£…é¥°å™¨ / L2 Cache Decorator
 *
 * @param option ç¼“å­˜é€‰é¡¹ / Cache options
 * @returns æ–¹æ³•è£…é¥°å™¨ / Method decorator
 *
 * åŠŸèƒ½è¯´æ˜ / Description:
 * ä¸ºæ–¹æ³•æ·»åŠ  L2 (Redis) ç¼“å­˜ï¼Œè·¨è¿›ç¨‹å…±äº«ç¼“å­˜
 * Adds L2 (Redis) cache to method, shares cache across processes
 *
 * ä½¿ç”¨åœºæ™¯ / Use Cases:
 * - ä¸­é¢‘è®¿é—®çš„ç”¨æˆ·æ•°æ® / Medium-frequency user data
 * - éœ€è¦è·¨è¿›ç¨‹å…±äº«çš„æ•°æ® / Data that needs cross-process sharing
 * - è¾ƒå¤§çš„æ•°æ®é›† / Larger datasets
 *
 * ç¤ºä¾‹ / Example:
 * ```typescript
 * @Service()
 * class UserService {
 *   @L2Cache({ ttlSeconds: 600 })
 *   async getUserProfile(userId: string) {
 *     return await this.userRepo.findById(userId);
 *   }
 *
 *   // åŠ¨æ€ TTL / Dynamic TTL
 *   @L2Cache({
 *     ttlSeconds: (get) => {
 *       const config = get(ConfigService);
 *       return config.getCacheTTL();
 *     }
 *   })
 *   async getProducts() {
 *     return await this.productRepo.findAll();
 *   }
 * }
 * ```
 */
export function L2Cache(option?: CacheOption) {
  return cache(option ?? {}, false);
}

/**
 * ç¼“å­˜è£…é¥°å™¨å·¥å‚å‡½æ•° / Cache Decorator Factory Function
 * L1Cache å’Œ L2Cache çš„å†…éƒ¨å®ç°
 * Internal implementation for L1Cache and L2Cache
 */
function cache({ key, ttlSeconds }: CacheOption, isL1: boolean) {
  return function (target: any, propertyKey: any, descriptor: PropertyDescriptor): void {
    const originalMethod = descriptor.value;

    // æ›¿æ¢åŸæ–¹æ³•ä¸ºå¸¦ç¼“å­˜çš„ç‰ˆæœ¬ / Replace original method with cached version
    descriptor.value = async function (...args: any[]) {
      // æ„é€ ç¼“å­˜é”®ï¼šè‡ªå®šä¹‰é”® æˆ– ç±»å.æ–¹æ³•å + å‚æ•° / Construct cache key: custom key or ClassName.methodName + args
      const param = [key ?? `${target.constructor.name}.${propertyKey}`, ...args];
      const svc = Container.get(CacheService);
      // æ ¹æ® isL1 è°ƒç”¨å¯¹åº”çš„ç¼“å­˜æ–¹æ³• / Call corresponding cache method based on isL1
      return isL1 ? svc.getL1(param, () => originalMethod.apply(this, args), await getTtlSeconds(ttlSeconds)) : svc.getL2(param, () => originalMethod.apply(this, args), await getTtlSeconds(ttlSeconds));
    };
  };
}

/**
 * è·å– TTL ç§’æ•° / Get TTL Seconds
 * å¤„ç† TTL ä¸ºæ•°å­—æˆ–å‡½æ•°çš„æƒ…å†µ
 * Handles TTL being number or function
 */
async function getTtlSeconds(val: number | TTLSecondFn | undefined) {
  if (typeof val === 'function') {
    // TTL æ˜¯å‡½æ•°ï¼Œè°ƒç”¨å®ƒè·å–åŠ¨æ€å€¼ / TTL is function, call it to get dynamic value
    return Promise.resolve(val((claz) => Container.get(claz)));
  } else {
    // TTL æ˜¯æ•°å­—æˆ– undefined / TTL is number or undefined
    return Promise.resolve(val);
  }
}
